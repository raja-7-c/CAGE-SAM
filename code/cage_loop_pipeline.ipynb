{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymFBiZLVZLow"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y3_YUJvZLoz"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import enum\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from spear.labeling import PreLabels\n",
        "import numpy as np\n",
        "from spear.cage import Cage\n",
        "from utils import custom_dataset, train_all_LF\n",
        "from generate_LF import get_variables\n",
        "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A1bbbh4ZLo1"
      },
      "source": [
        "### Declaring ClassLabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uG40SdiLZLo1"
      },
      "outputs": [],
      "source": [
        "ABSTAIN = None\n",
        "\n",
        "class ClassLabels(enum.Enum):\n",
        "    LYMPHOCYTE= 0\n",
        "    NONLYMPHOCYTE = 1\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlrnD7hDZLo1"
      },
      "source": [
        "### Defining Labelling Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7uvTC2OZLo2"
      },
      "source": [
        "#### LFs for Class 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL2DrKa3ZLo2"
      },
      "outputs": [],
      "source": [
        "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
        "import re\n",
        "# path = \"/home/akshit/Desktop/MICCAI/data/models/\"\n",
        "path = \"/home/raja/Desktop/MICCAI/data/models/100/\"\n",
        "\n",
        "# SVM\n",
        "@continuous_scorer()\n",
        "def svm_0(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
        "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
        "    confidence_scores = svm.predict_proba([x])\n",
        "    # print(confidence_scores)\n",
        "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
        "\n",
        "@labeling_function(cont_scorer=svm_0, label=ClassLabels.LYMPHOCYTE)\n",
        "def LF_svm_0(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
        "    \n",
        "    if svm.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
        "    else: \n",
        "        return ABSTAIN\n",
        "\n",
        "# Random Forest\n",
        "@continuous_scorer()\n",
        "def rf_0(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
        "    confidence_scores = rf.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) \n",
        "\n",
        "@labeling_function(cont_scorer=rf_0, label=ClassLabels.LYMPHOCYTE)\n",
        "def LF_rf_0(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
        "    \n",
        "    if rf.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.LYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n",
        "\n",
        "# KNN\n",
        "@continuous_scorer()\n",
        "def knn_0(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
        "    confidence_scores = knn.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) \n",
        "\n",
        "\n",
        "@labeling_function(cont_scorer=knn_0, label=ClassLabels.LYMPHOCYTE)\n",
        "def LF_knn_0(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
        "    \n",
        "    if knn.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.LYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n",
        "\n",
        "# Decision Tree \n",
        "@continuous_scorer()\n",
        "def dt_0(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
        "    confidence_scores = dt.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) \n",
        "\n",
        "@labeling_function(cont_scorer=dt_0, label=ClassLabels.LYMPHOCYTE)\n",
        "def LF_dt_0(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
        "    \n",
        "    if dt.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.LYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n",
        "\n",
        "# Logistic Regression\n",
        "@continuous_scorer()\n",
        "def lr_0(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
        "    confidence_scores = lr.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) \n",
        "\n",
        "@labeling_function(cont_scorer=lr_0, label=ClassLabels.LYMPHOCYTE)\n",
        "def LF_lr_0(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
        "    \n",
        "    if lr.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.LYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ter2h8BMZLo3"
      },
      "source": [
        "#### LFs for Class 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76LHRFvfZLo4"
      },
      "outputs": [],
      "source": [
        "# SVM\n",
        "@continuous_scorer()\n",
        "def svm_1(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
        "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
        "    confidence_scores = svm.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
        "\n",
        "@labeling_function(cont_scorer=svm_1, label=ClassLabels.NONLYMPHOCYTE)\n",
        "def LF_svm_1(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
        "    \n",
        "    if svm.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.NONLYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n",
        "\n",
        "# Random Forest\n",
        "@continuous_scorer()\n",
        "def rf_1(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
        "    confidence_scores = rf.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) \n",
        "\n",
        "@labeling_function(cont_scorer=rf_1, label=ClassLabels.NONLYMPHOCYTE)\n",
        "def LF_rf_1(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
        "    \n",
        "    if rf.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.NONLYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n",
        "\n",
        "# KNN\n",
        "@continuous_scorer()\n",
        "def knn_1(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
        "    confidence_scores = knn.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) \n",
        "\n",
        "\n",
        "@labeling_function(cont_scorer=knn_1, label=ClassLabels.NONLYMPHOCYTE)\n",
        "def LF_knn_1(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
        "    \n",
        "    if knn.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.NONLYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n",
        "\n",
        "# Decision Tree \n",
        "@continuous_scorer()\n",
        "def dt_1(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
        "    confidence_scores = dt.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) \n",
        "\n",
        "@labeling_function(cont_scorer=dt_1, label=ClassLabels.NONLYMPHOCYTE)\n",
        "def LF_dt_1(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
        "    \n",
        "    if dt.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.NONLYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n",
        "\n",
        "# Logistic Regression\n",
        "@continuous_scorer()\n",
        "def lr_1(x,**kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
        "    confidence_scores = lr.predict_proba([x])\n",
        "\n",
        "    return float(confidence_scores[0][1]) \n",
        "\n",
        "@labeling_function(cont_scorer=lr_1, label=ClassLabels.NONLYMPHOCYTE)\n",
        "def LF_lr_1(x, **kwargs):\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array(x).flatten()  \n",
        "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
        "    \n",
        "    if lr.predict_proba([x])[0][1]>0.8: \n",
        "        return ClassLabels.NONLYMPHOCYTE\n",
        "    else: \n",
        "        return ABSTAIN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T22ON_yZLo4"
      },
      "source": [
        "## Aggregating LFs & Labelling dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEYyQZntZLo5"
      },
      "source": [
        "### LFSet\n",
        "Placeholder for declared LFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y-f0g9MZLo5"
      },
      "outputs": [],
      "source": [
        "from spear.labeling import LFSet\n",
        "\n",
        "LFS = [\n",
        "    LF_svm_0,\n",
        "    LF_rf_0,\n",
        "    LF_knn_0,\n",
        "    LF_dt_0,\n",
        "    LF_lr_0,\n",
        "    LF_svm_1,\n",
        "    LF_rf_1,\n",
        "    LF_knn_1,\n",
        "    LF_dt_1,\n",
        "    LF_lr_1,  \n",
        "]\n",
        "\n",
        "\n",
        "rules = LFSet(\"BM_LF\")\n",
        "rules.add_lf_list(LFS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfHc9V6zZLo5"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmKsF32nZLo6"
      },
      "outputs": [],
      "source": [
        "from utils import custom_dataset, train_all_LF\n",
        "from generate_LF import get_variables\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "\n",
        "classes,label_frac,data_path,save_path = get_variables()\n",
        "dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)\n",
        "\n",
        "# 5% of Val Set to Test CNN after every iteration\n",
        "x_val, dummy1, y_val, dummy2 = train_test_split(dataset[\"val_images\"], dataset[\"val_labels\"], train_size=1)\n",
        "\n",
        "x_val = np.array(x_val).reshape(-1, 30, 30, 3)\n",
        "x_val = np.array(x_val).reshape(-1, 30, 30, 3)\n",
        "x_val = x_val.astype(\"float32\") / 255\n",
        "y_val = [int(i) for i in y_val] \n",
        "y_val = np_utils.to_categorical(y_val, num_classes=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdcmO9cGZLo6"
      },
      "source": [
        "## Cage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogvOdFiUZLo6"
      },
      "outputs": [],
      "source": [
        "def cage_loop(LFS, max_iters=10, threshold=10**-5, img_per_class = 150):\n",
        "    from keras.utils import np_utils\n",
        "    # Paths\n",
        "    log_path_cage = './cage_loop/log.txt' \n",
        "    params_path = None\n",
        "    path_json = \"./cage_loop/labels.json\"\n",
        "    U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
        "    L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
        "\n",
        "    # Loading Data\n",
        "    classes,label_frac,data_path,save_path = get_variables()\n",
        "    print(\"Classes used in expt:\",classes)\n",
        "    dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
        "\n",
        "    xu = np.array(dataset['test_images'])\n",
        "    yu = np.array(dataset['test_labels'])\n",
        "    print(np.shape(xu),np.shape(yu))\n",
        "    # Creating rules\n",
        "    n_lfs = len(LFS)\n",
        "    rules = LFSet(\"BM_LF\")\n",
        "    rules.add_lf_list(LFS)\n",
        "    \n",
        "    confidence_list = []\n",
        "    val_scores = []\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        # Train Models in LFs\n",
        "        train_all_LF(x,y,len(classes),save_path,label_frac)\n",
        "\n",
        "        # Unlabelled\n",
        "        u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
        "                                    data=xu,\n",
        "                                    rules=rules,\n",
        "                                    labels_enum=ClassLabels,\n",
        "                                    num_classes=len(classes))\n",
        "        # Lu,Su = u_noisy_labels.get_labels()\n",
        "        u_noisy_labels.generate_pickle(U_path_pkl)\n",
        "\n",
        "        # Labelled\n",
        "        l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
        "                                    data=x,\n",
        "                                    gold_labels=y,\n",
        "                                    rules=rules,\n",
        "                                    labels_enum=ClassLabels,\n",
        "                                    num_classes=len(classes))\n",
        "        # Ll,Sl = l_noisy_labels.get_labels()\n",
        "        l_noisy_labels.generate_pickle(L_path_pkl)\n",
        "        l_noisy_labels.generate_json(path_json)\n",
        "\n",
        "\n",
        "        # Cage\n",
        "        cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
        "        if params_path is not None: \n",
        "            cage.load_params(load_path = params_path)\n",
        "        else:\n",
        "            params_path = './cage_loop/params.pkl' \n",
        "        \n",
        "        probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
        "        labels = np.argmax(probs, 1)\n",
        "\n",
        "        print(labels)\n",
        "\n",
        "        values, frequency = np.unique(yu, return_counts=True)\n",
        "        for values, frequency in zip(values, frequency):\n",
        "            print(f\"Labels of Lake Class {values}: {frequency}\")\n",
        "\n",
        "        values, frequency = np.unique(y, return_counts=True)\n",
        "        for values, frequency in zip(values, frequency):\n",
        "            print(f\"Labels of Labelled Set {values}: {frequency}\")\n",
        "        \n",
        "        print(\"=\"*45)\n",
        "        print(\"Iteration\",i)\n",
        "        print(\"Shape of Labeled Data:\",x.shape)\n",
        "        print(\"Shape of Unlabeled Data:\",xu.shape)\n",
        "        print(\"Accuracy on unlabelled images:\",accuracy_score(labels,yu)*100)\n",
        "        print(\"=\"*45)\n",
        "        \n",
        "        cage.save_params(save_path = params_path)\n",
        "\n",
        "        confidence = np.array([np.max(i) for i in probs])\n",
        "        confidence_list.append(confidence)\n",
        "        print(i,probs.shape)\n",
        "\n",
        "        # Getting indices of probabilities in decreasing order\n",
        "        idx = np.argsort(confidence)\n",
        "        idx = idx[::-1] \n",
        "\n",
        "        # Number of images per class (5%)\n",
        "        # img_per_class = int(0.05*len(confidence)/len(classes))\n",
        "\n",
        "        # Number of images per class (50)\n",
        "        \n",
        "        \n",
        "        print(\"Num img per class =\",img_per_class)\n",
        "\n",
        "        pop_list = [] #list of indices of images to be added\n",
        "        label_count = []\n",
        "\n",
        "        for j in idx:\n",
        "            if confidence[j]>threshold and label_count.count(labels[j])<img_per_class:\n",
        "                pop_list.append(j)\n",
        "                label_count.append(labels[j])\n",
        "        \n",
        "        print(\"Number of images getting transferred:\", len(pop_list))\n",
        "        print('Accuracy of Pseudo-labelled img added to dataset:', accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
        "        \n",
        "        x = np.append(x,xu[pop_list], axis=0)\n",
        "        y = np.append(y,labels[pop_list], axis=0)        \n",
        "        xu = np.delete(xu,pop_list, axis=0)\n",
        "        yu = np.delete(yu,pop_list, axis=0)\n",
        "\n",
        "        if len(pop_list)<5:\n",
        "            break\n",
        "\n",
        "        # Deleting variables\n",
        "        del u_noisy_labels\n",
        "        del l_noisy_labels\n",
        "        del cage\n",
        "\n",
        "        classes,label_frac,data_path,save_path = get_variables()\n",
        "\n",
        "        # x_train = x\n",
        "        # x_train = np.array(x_train).reshape(-1, 28, 28, 3)\n",
        "        # x_train = x_train.astype(\"float32\") / 255\n",
        "        # y_train = [int(i) for i in y]\n",
        "        # y_train = np_utils.to_categorical(y_train, len(classes))\n",
        "        # batch_size = 128\n",
        "        # epochs = 25\n",
        "        # model = create_cnn(num_classes = 3)\n",
        "        # model.summary()\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        # model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "        # model.save(f'/home/akshit/Desktop/MICCAI/code/cnn/cage_trained_{i}.h5')\n",
        "        # # model = load_model(f'/home/akshit/Desktop/MICCAI/code/cnn/cage_trained_{i}.h5')\n",
        "        # score = model.evaluate(x_val, y_val, verbose = 0)\n",
        "        # val_scores.append(score[1]*100)\n",
        "        # print(f\"CNN Test accuracy on Lake Set for iteration{i}: \", val_scores[i])\n",
        "        # # if i>0 and val_scores[i]<val_scores[i-1]:\n",
        "        # #     break\n",
        "\n",
        "\n",
        "    return x,y,xu,yu,confidence_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obs1R--OZLo7",
        "outputId": "ae03093a-6719-4cc5-d7be-ed7a72be83ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes used in expt: [0, 1]\n",
            "(60, 30, 30, 3) (60,)\n",
            "Trained & Saved 6 models\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained & Saved 6 models\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [00:01<00:00, 31.43it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 36.87it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 53.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final_test_accuracy_score: 1.0\n",
            "test_average_metric: macro\tfinal_test_f1_score: 1.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            "Labels of Lake Class 0: 30\n",
            "Labels of Lake Class 1: 30\n",
            "Labels of Labelled Set 0: 50\n",
            "Labels of Labelled Set 1: 50\n",
            "=============================================\n",
            "Iteration 0\n",
            "Shape of Labeled Data: (100, 30, 30, 3)\n",
            "Shape of Unlabeled Data: (60, 30, 30, 3)\n",
            "Accuracy on unlabelled images: 86.66666666666667\n",
            "=============================================\n",
            "0 (60, 2)\n",
            "Num img per class = 10\n",
            "Number of images getting transferred: 20\n",
            "Accuracy of Pseudo-labelled img added to dataset: 100.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#  img_per_class: num images added per loop per class\n",
        "x,y,xu,yu,confidence_list = cage_loop(LFS, max_iters=1, threshold=10**-10,  img_per_class = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZksVzEHZLo7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "\n",
        "image_folder = '/home/raja/Desktop/segment-anything/output/test/'\n",
        "image_files = os.listdir(image_folder)\n",
        "\n",
        "image_data = []\n",
        "image_names = []\n",
        "for file in image_files:\n",
        "    image_path = os.path.join(image_folder, file)\n",
        "    image = imageio.imread(image_path)\n",
        "    resized_image = resize(image, (30, 30, 3))\n",
        "    image_data.append(resized_image)\n",
        "    image_names.append(file)\n",
        "\n",
        "xuu = (np.array(image_data) * 255).astype(np.uint8)\n",
        "\n",
        "print(xuu.shape)  # (num_images, 30, 30, 3)\n",
        "#print(image_names)  # list of image file names in the same order as x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSt3U_x3ZLo8"
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "# Paths\n",
        "log_path_cage = './cage_loop/log.txt' \n",
        "params_path = None\n",
        "path_json = \"./cage_loop/labels.json\"\n",
        "U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
        "L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
        "\n",
        "# Loading Data\n",
        "classes,label_frac,data_path,save_path = get_variables()\n",
        "#print(\"Classes used in expt:\",classes)\n",
        "dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
        "xu = np.array(dataset['test_images'])\n",
        "\n",
        "# Unlabelled\n",
        "u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
        "                            data=xuu,\n",
        "                            rules=rules,\n",
        "                            labels_enum=ClassLabels,\n",
        "                            num_classes=len(classes))\n",
        "# Lu,Su = u_noisy_labels.get_labels()\n",
        "u_noisy_labels.generate_pickle(U_path_pkl)\n",
        "\n",
        "# Labelled\n",
        "l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
        "                            data=x,\n",
        "                            gold_labels=y,\n",
        "                            rules=rules,\n",
        "                            labels_enum=ClassLabels,\n",
        "                            num_classes=len(classes))\n",
        "# Ll,Sl = l_noisy_labels.get_labels()\n",
        "l_noisy_labels.generate_pickle(L_path_pkl)\n",
        "l_noisy_labels.generate_json(path_json)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(np.shape(xuu))\n",
        "# Creating rules\n",
        "n_lfs = len(LFS)\n",
        "rules = LFSet(\"BM_LF\")\n",
        "rules.add_lf_list(LFS)\n",
        "\n",
        "# Cage\n",
        "cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
        "if params_path is not None: \n",
        "    cage.load_params(load_path = params_path)\n",
        "else:\n",
        "    params_path = './cage_loop/params.pkl' \n",
        "probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
        "#probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
        "labels = np.argmax(probs, 1)\n",
        "\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH1-2unUZLo8"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Combine image names and predicted labels\n",
        "data = zip(image_names, labels)\n",
        "\n",
        "# Write to CSV file\n",
        "with open('/home/raja/Desktop/MICCAI/predictions.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Image Name', 'Label'])\n",
        "    for row in data:\n",
        "        writer.writerow(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imnNGZdeZLo8"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "# Define input and output file names\n",
        "input_file = '/home/raja/Desktop/MICCAI/predictions.csv'\n",
        "output_file = '/home/raja/Desktop/MICCAI/output.csv'\n",
        "\n",
        "# Define dictionary to store counts for each image\n",
        "image_counts = {}\n",
        "\n",
        "# Define regular expression to extract image number from filename\n",
        "img_regex = re.compile(r'img_(\\d+)_cropped_\\d+.jpg')\n",
        "\n",
        "# Read input file and count labels for each image\n",
        "with open(input_file, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # skip header row\n",
        "    for row in reader:\n",
        "        image_name, label = row\n",
        "        img_match = img_regex.match(image_name)\n",
        "        if img_match:\n",
        "            image_number = int(img_match.group(1))\n",
        "            if image_number in image_counts:\n",
        "                if label == '0':\n",
        "                    image_counts[image_number][0] += 1\n",
        "                else:\n",
        "                    image_counts[image_number][1] += 1\n",
        "            else:\n",
        "                if label == '0':\n",
        "                    image_counts[image_number] = {0: 1, 1: 0}\n",
        "                else:\n",
        "                    image_counts[image_number] = {0: 0, 1: 1}\n",
        "\n",
        "# Write output file with counts for each image\n",
        "with open(output_file, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Image', 'Lymphocyte', 'Non-Lymphocyte'])\n",
        "    for image_number, counts in sorted(image_counts.items()):\n",
        "        writer.writerow(['img_{}'.format(image_number), counts[0], counts[1]])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cage",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f9f5b4396ae54b339dce7091723dfd2c38ad833227f8e97d2a6323021886247d"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}