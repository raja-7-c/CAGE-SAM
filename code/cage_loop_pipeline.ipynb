{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring ClassLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    LYMPHOCYTE= 0\n",
    "    NONLYMPHOCYTE = 1\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Labelling Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "# path = \"/home/akshit/Desktop/MICCAI/data/models/\"\n",
    "path = \"/home/raja/Desktop/MICCAI/data/models/100/\"\n",
    "\n",
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_0, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_svm_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_0, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_rf_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    \n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_0, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_knn_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    \n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_0, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_dt_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    \n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_0, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_lr_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    \n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.LYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_svm_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=rf_1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_rf_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    \n",
    "    if rf.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_knn_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    \n",
    "    if knn.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree \n",
    "@continuous_scorer()\n",
    "def dt_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=dt_1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_dt_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    \n",
    "    if dt.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) \n",
    "\n",
    "@labeling_function(cont_scorer=lr_1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_lr_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    \n",
    "    if lr.predict_proba([x])[0][1]>0.8: \n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating LFs & Labelling dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFSet\n",
    "Placeholder for declared LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    LF_svm_0,\n",
    "    LF_rf_0,\n",
    "    LF_knn_0,\n",
    "    LF_dt_0,\n",
    "    LF_lr_0,\n",
    "    LF_svm_1,\n",
    "    LF_rf_1,\n",
    "    LF_knn_1,\n",
    "    LF_dt_1,\n",
    "    LF_lr_1,  \n",
    "]\n",
    "\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)\n",
    "\n",
    "# 5% of Val Set to Test CNN after every iteration\n",
    "x_val, dummy1, y_val, dummy2 = train_test_split(dataset[\"val_images\"], dataset[\"val_labels\"], train_size=1)\n",
    "\n",
    "x_val = np.array(x_val).reshape(-1, 30, 30, 3)\n",
    "x_val = np.array(x_val).reshape(-1, 30, 30, 3)\n",
    "x_val = x_val.astype(\"float32\") / 255\n",
    "y_val = [int(i) for i in y_val] \n",
    "y_val = np_utils.to_categorical(y_val, num_classes=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cage_loop(LFS, max_iters=10, threshold=10**-5, img_per_class = 150):\n",
    "    from keras.utils import np_utils\n",
    "    # Paths\n",
    "    log_path_cage = './cage_loop/log.txt' \n",
    "    params_path = None\n",
    "    path_json = \"./cage_loop/labels.json\"\n",
    "    U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
    "    L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
    "\n",
    "    # Loading Data\n",
    "    classes,label_frac,data_path,save_path = get_variables()\n",
    "    print(\"Classes used in expt:\",classes)\n",
    "    dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
    "\n",
    "    xu = np.array(dataset['test_images'])\n",
    "    yu = np.array(dataset['test_labels'])\n",
    "    print(np.shape(xu),np.shape(yu))\n",
    "    # Creating rules\n",
    "    n_lfs = len(LFS)\n",
    "    rules = LFSet(\"BM_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "    \n",
    "    confidence_list = []\n",
    "    val_scores = []\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        # Train Models in LFs\n",
    "        train_all_LF(x,y,len(classes),save_path,label_frac)\n",
    "\n",
    "        # Unlabelled\n",
    "        u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                                    data=xu,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Lu,Su = u_noisy_labels.get_labels()\n",
    "        u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n",
    "        # Labelled\n",
    "        l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "                                    data=x,\n",
    "                                    gold_labels=y,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Ll,Sl = l_noisy_labels.get_labels()\n",
    "        l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "        l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "        # Cage\n",
    "        cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "        if params_path is not None: \n",
    "            cage.load_params(load_path = params_path)\n",
    "        else:\n",
    "            params_path = './cage_loop/params.pkl' \n",
    "        \n",
    "        probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "        labels = np.argmax(probs, 1)\n",
    "\n",
    "        values, frequency = np.unique(yu, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Lake Class {values}: {frequency}\")\n",
    "\n",
    "        values, frequency = np.unique(y, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Labelled Set {values}: {frequency}\")\n",
    "        \n",
    "        print(\"=\"*45)\n",
    "        print(\"Iteration\",i)\n",
    "        print(\"Shape of Labeled Data:\",x.shape)\n",
    "        print(\"Shape of Unlabeled Data:\",xu.shape)\n",
    "        print(\"Accuracy on unlabelled images:\",accuracy_score(labels,yu)*100)\n",
    "        print(\"=\"*45)\n",
    "        \n",
    "        cage.save_params(save_path = params_path)\n",
    "\n",
    "        confidence = np.array([np.max(i) for i in probs])\n",
    "        confidence_list.append(confidence)\n",
    "        print(i,probs.shape)\n",
    "\n",
    "        # Getting indices of probabilities in decreasing order\n",
    "        idx = np.argsort(confidence)\n",
    "        idx = idx[::-1] \n",
    "\n",
    "        # Number of images per class (5%)\n",
    "        # img_per_class = int(0.05*len(confidence)/len(classes))\n",
    "\n",
    "        # Number of images per class (50)\n",
    "        \n",
    "        \n",
    "        print(\"Num img per class =\",img_per_class)\n",
    "\n",
    "        pop_list = [] #list of indices of images to be added\n",
    "        label_count = []\n",
    "\n",
    "        for j in idx:\n",
    "            if confidence[j]>threshold and label_count.count(labels[j])<img_per_class:\n",
    "                pop_list.append(j)\n",
    "                label_count.append(labels[j])\n",
    "        \n",
    "        print(\"Number of images getting transferred:\", len(pop_list))\n",
    "        print('Accuracy of Pseudo-labelled img added to dataset:', accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "        \n",
    "        x = np.append(x,xu[pop_list], axis=0)\n",
    "        y = np.append(y,labels[pop_list], axis=0)        \n",
    "        xu = np.delete(xu,pop_list, axis=0)\n",
    "        yu = np.delete(yu,pop_list, axis=0)\n",
    "\n",
    "        if len(pop_list)<5:\n",
    "            break\n",
    "\n",
    "        # Deleting variables\n",
    "        del u_noisy_labels\n",
    "        del l_noisy_labels\n",
    "        del cage\n",
    "\n",
    "        classes,label_frac,data_path,save_path = get_variables()\n",
    "\n",
    "        # x_train = x\n",
    "        # x_train = np.array(x_train).reshape(-1, 28, 28, 3)\n",
    "        # x_train = x_train.astype(\"float32\") / 255\n",
    "        # y_train = [int(i) for i in y]\n",
    "        # y_train = np_utils.to_categorical(y_train, len(classes))\n",
    "        # batch_size = 128\n",
    "        # epochs = 25\n",
    "        # model = create_cnn(num_classes = 3)\n",
    "        # model.summary()\n",
    "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        # model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "        # model.save(f'/home/akshit/Desktop/MICCAI/code/cnn/cage_trained_{i}.h5')\n",
    "        # # model = load_model(f'/home/akshit/Desktop/MICCAI/code/cnn/cage_trained_{i}.h5')\n",
    "        # score = model.evaluate(x_val, y_val, verbose = 0)\n",
    "        # val_scores.append(score[1]*100)\n",
    "        # print(f\"CNN Test accuracy on Lake Set for iteration{i}: \", val_scores[i])\n",
    "        # # if i>0 and val_scores[i]<val_scores[i-1]:\n",
    "        # #     break\n",
    "\n",
    "\n",
    "    return x,y,xu,yu,confidence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used in expt: [0, 1]\n",
      "(22, 30, 30, 3) (22,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 27.52it/s]\n",
      "100%|██████████| 122/122 [00:04<00:00, 30.06it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 52.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_test_accuracy_score: 1.0\n",
      "test_average_metric: macro\tfinal_test_f1_score: 1.0\n",
      "Labels of Lake Class 0: 11\n",
      "Labels of Lake Class 1: 11\n",
      "Labels of Labelled Set 0: 61\n",
      "Labels of Labelled Set 1: 61\n",
      "=============================================\n",
      "Iteration 0\n",
      "Shape of Labeled Data: (122, 30, 30, 3)\n",
      "Shape of Unlabeled Data: (22, 30, 30, 3)\n",
      "Accuracy on unlabelled images: 95.45454545454545\n",
      "=============================================\n",
      "0 (22, 2)\n",
      "Num img per class = 10\n",
      "Number of images getting transferred: 20\n",
      "Accuracy of Pseudo-labelled img added to dataset: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#  img_per_class: num images added per loop per class\n",
    "x,y,xu,yu,confidence_list = cage_loop(LFS, max_iters=1, threshold=10**-10,  img_per_class = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f5b4396ae54b339dce7091723dfd2c38ad833227f8e97d2a6323021886247d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
